{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports and Setups"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import plotnine as p9\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "import transformer\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn import metrics\r\n",
    "from fairnesTester import FairnessTester\r\n",
    "from sklearn.pipeline import FeatureUnion\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from fairnesTester import FairnessTester\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\r\n",
    "\r\n",
    "#pipelines and transformer\r\n",
    "\r\n",
    "cat_trans = Pipeline(steps=[\r\n",
    "    (\"selector\", transformer.DataSelector(\"object\")),\r\n",
    "    (\"one_hot\", preprocessing.OneHotEncoder())\r\n",
    "])\r\n",
    "num_trans = Pipeline(steps=[\r\n",
    "    (\"selector\", transformer.DataSelector(\"number\")),\r\n",
    "    (\"scaler\", StandardScaler() )\r\n",
    "])\r\n",
    "\r\n",
    "pre_pipe = FeatureUnion(transformer_list=[\r\n",
    "    (\"cat\", cat_trans),\r\n",
    "    (\"num\", num_trans)\r\n",
    "])\r\n",
    "\r\n",
    "lb = LabelBinarizer()\r\n",
    "del_nan = transformer.DeleteNAN(\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing and preparing the data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adult Income Data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = \"Datasets/adult.data\"\r\n",
    "names = [\"age\", \"workclass\", \"fnlwgt\",\"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"class\"]\r\n",
    "train = pd.read_csv(filename, names=names)\r\n",
    "test = test = pd.read_csv(\"Datasets/adult.test\", names=names)\r\n",
    "\r\n",
    "del_nan.set_nan_char(\" ?\")\r\n",
    "train = del_nan.transform(train)\r\n",
    "test = del_nan.transform(test)\r\n",
    "\r\n",
    "train[\"class\"] = lb.fit_transform(train[\"class\"])\r\n",
    "test[\"class\"] = lb.fit_transform(test[\"class\"])\r\n",
    "\r\n",
    "train_data = pre_pipe.fit_transform(train.drop(\"class\", axis=1))\r\n",
    "train_labels = train[\"class\"]\r\n",
    "\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "test_labels = test[\"class\"]\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"Adult_Income\"\r\n",
    "priv_val = \" Male\"\r\n",
    "unpriv_val = \" Female\"\r\n",
    "protected_att = \"sex\"\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## German Credit Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = \"Datasets/german.data\"\r\n",
    "names = [\"status existing account\",\"duration\", \"credit history\", \"purpose\", \"credit amount\", \"savings\", \"employment since\", \"installment rate\", \"sex\", \"other debtors\", \"residence since\", \"property\", \"age\", \"installment plans\", \"housing\", \"num existing credits\", \"job\", \"no of pople liable\", \"telephone\", \"foreign worker\", \"class\" ]\r\n",
    "data = pd.read_csv(filename, sep=\" \", names =names)\r\n",
    "\r\n",
    "data[\"class\"] = lb.fit_transform(data[\"class\"])\r\n",
    "\r\n",
    "data, test, train_labels, test_labels = train_test_split(data, data[\"class\"], random_state=42)\r\n",
    "\r\n",
    "train_data = pre_pipe.fit_transform(data.drop(\"class\", axis=1))\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "\r\n",
    "#transform for Fairness tester\r\n",
    "test[\"sex\"].replace([\"A91\",\"A93\", \"A94\"],\"m\",inplace=True)\r\n",
    "test[\"sex\"].replace([\"A92\",\"A95\"],\"f\",inplace=True)\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"German_Credit\"\r\n",
    "priv_val = \"m\"\r\n",
    "unpriv_val = \"f\"\r\n",
    "protected_att = \"sex\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Default of Creddit Card Payments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = \"Datasets/default of credit.xls\"\r\n",
    "data_inp = pd.read_excel(filename, dtype={\"X1\": int,\"X2\": object,\"X3\": object,\"X4\": object,\"X5\": object,\"X6\": object,\"X7\": object,\"X8\": object,\"X9\": object,\"X10\": object,\"X11\": object,\"X12\": int,\"X13\": int,\"X14\": int,\"X15\": int,\"X16\": int,\"X17\": int,\"X23\": int,\"X18\": int,\"X19\": int,\"X20\": int,\"X21\": int,\"X22\": int})\r\n",
    "\r\n",
    "data_inp = data_inp.rename(columns={\"Y\": \"class\"})\r\n",
    "\r\n",
    "data, test, train_labels, test_labels = train_test_split(data_inp, data_inp[\"class\"], random_state=42)\r\n",
    "\r\n",
    "pre_pipe.fit(data_inp.drop(\"class\", axis=1))\r\n",
    "train_data = pre_pipe.transform(data.drop(\"class\", axis=1))\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"default_of_credit\"\r\n",
    "priv_val = 1 #male\r\n",
    "unpriv_val = 2 #female\r\n",
    "protected_att = \"X2\"\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rici vs Stefano Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = \"Datasets/ricci.csv\"\r\n",
    "data_inp = pd.read_csv(filename).drop(\"Unnamed: 0\", axis=1)\r\n",
    "#applicants with combine >= 70 pass\r\n",
    "#read paper Did the Results of Promotion Exams Have a Disparate Impact on Minorities? Using Statistical Evidence in Ricci v. DeStefano\r\n",
    "data_inp.rename(columns={\"Combine\": \"class\"}, inplace=True)\r\n",
    "\r\n",
    "data_inp.loc[data_inp[\"class\"]>=70, \"class\"] = 1\r\n",
    "data_inp.loc[(data_inp[\"class\"]<70) & (data_inp[\"class\"]>1), \"class\"] = 0\r\n",
    "\r\n",
    "data, test, train_labels, test_labels = train_test_split(data_inp, data_inp[\"class\"], random_state=42)\r\n",
    "\r\n",
    "pre_pipe.fit(data_inp.drop(\"class\", axis=1))\r\n",
    "train_data = pre_pipe.transform(data.drop(\"class\", axis=1))\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "\r\n",
    "#transform for Fairness tester\r\n",
    "test[\"Race\"].replace([\"H\",\"B\",],\"NW\",inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"ricci_vs_stefano\"\r\n",
    "priv_val = \"W\" #white\r\n",
    "unpriv_val = \"NW\" #not white\r\n",
    "protected_att = \"Race\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hepatitis dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Heart Disease Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = \"Datasets/processed.cleveland.data\"\r\n",
    "names = [\"age\", \"sex\", 3,4,5,6,7,8,9,10,11,12,13,\"class\"]\r\n",
    "data_inp = pd.read_csv(filename, names=names)\r\n",
    "\r\n",
    "\r\n",
    "data_inp.loc[data_inp[\"class\"]>=1, \"class\"] = 1 #existing heart disase\r\n",
    "\r\n",
    "data, test, train_labels, test_labels = train_test_split(data_inp, data_inp[\"class\"], random_state=42)\r\n",
    "\r\n",
    "pre_pipe.fit(data_inp.drop(\"class\", axis=1))\r\n",
    "train_data = pre_pipe.transform(data.drop(\"class\", axis=1))\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"heart_diseases_dataset\"\r\n",
    "priv_val = 1 #male\r\n",
    "unpriv_val = 0 #female\r\n",
    "protected_att = \"sex\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Heart Failure Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = \"Datasets/heart_failure.csv\"\r\n",
    "data_inp = pd.read_csv(filename)\r\n",
    "data_inp.rename(columns={\"DEATH_EVENT\":\"class\"}, inplace=True)\r\n",
    "\r\n",
    "data, test, train_labels, test_labels = train_test_split(data_inp, data_inp[\"class\"], random_state=42)\r\n",
    "\r\n",
    "\r\n",
    "pre_pipe.fit(data_inp.drop(\"class\", axis=1))\r\n",
    "train_data = pre_pipe.transform(data.drop(\"class\", axis=1))\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"heart_failure_dataset\"\r\n",
    "priv_val = 1 #male\r\n",
    "unpriv_val = 0 #female\r\n",
    "protected_att = \"sex\"\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Student Performance Data Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "filename = \"Datasets/student-por.csv\"\r\n",
    "data_inp = pd.read_csv(filename, sep=\";\")\r\n",
    "\r\n",
    "data_inp.drop([\"G1\",\"G2\"],axis=1,inplace=True)\r\n",
    "data_inp.rename(columns={\"G3\":\"class\"},inplace=True)\r\n",
    "\r\n",
    "data_inp.loc[(data_inp[\"class\"]<10), \"class\"] = 0 #failed\r\n",
    "data_inp.loc[data_inp[\"class\"]>=10, \"class\"] = 1 #passed\r\n",
    "\r\n",
    "\r\n",
    "data, test, train_labels, test_labels = train_test_split(data_inp, data_inp[\"class\"], random_state=42)\r\n",
    "\r\n",
    "\r\n",
    "pre_pipe.fit(data_inp.drop(\"class\", axis=1))\r\n",
    "train_data = pre_pipe.transform(data.drop(\"class\", axis=1))\r\n",
    "test_data = pre_pipe.transform(test.drop(\"class\", axis=1))\r\n",
    "\r\n",
    "\r\n",
    "#attribute for Fairness tester\r\n",
    "dataset_name = \"student_performance_dataset\"\r\n",
    "priv_val = \"M\" #male\r\n",
    "unpriv_val = \"F\" #female\r\n",
    "protected_att = \"sex\"\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tree = DecisionTreeClassifier()\r\n",
    "tree.fit(train_data,train_labels)\r\n",
    "\r\n",
    "tree_pred = tree.predict(test_data)\r\n",
    "test[\"prediction\"] = tree_pred\r\n",
    "dataset_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "forest = RandomForestClassifier()\r\n",
    "forest.fit(train_data,train_labels)\r\n",
    "\r\n",
    "forest_pred = forest.predict(test_data)\r\n",
    "test[\"prediction\"] = forest_pred\r\n",
    "dataset_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest-Neighbour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn = KNeighborsClassifier(3)\r\n",
    "knn.fit(train_data,train_labels)\r\n",
    "\r\n",
    "knn_pred = knn.predict(test_data)\r\n",
    "test[\"prediction\"] = knn_pred\r\n",
    "dataset_name "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#nochmal dringend anschauen\r\n",
    "svc = SVC(kernel=\"rbf\", C=0.025, probability=True) \r\n",
    "svc.fit(train_data,train_labels)\r\n",
    "\r\n",
    "svc_pred = svc.predict(test_data)\r\n",
    "test[\"prediction\"] = svc_pred\r\n",
    "dataset_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ada Boost "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ada = AdaBoostClassifier()\r\n",
    "svc.fit(train_data,train_labels)\r\n",
    "\r\n",
    "svc_pred = svc.predict(test_data)\r\n",
    "test[\"prediction\"] = svc_pred\r\n",
    "dataset_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian NB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gnb = GaussianNB()\r\n",
    "gnb.fit(train_data.toarray(),train_labels)\r\n",
    "\r\n",
    "gnb_pred = gnb.predict(test_data.toarray())\r\n",
    "test[\"prediction\"] = gnb_pred\r\n",
    "dataset_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Proccess Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gpc = GaussianProcessClassifier()\r\n",
    "gpc.fit(train_data.toarray(),train_labels)\r\n",
    "\r\n",
    "gpc_pred = gpc.predict(test_data.toarray())\r\n",
    "test[\"prediction\"] = gpc_pred\r\n",
    "gpc.__class__.__name__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifier List\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "classifiers = [DecisionTreeClassifier(),RandomForestClassifier(),SVC(),AdaBoostClassifier(),KNeighborsClassifier(5), GaussianNB()]\r\n",
    "model_names = []\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "for model in classifiers:\r\n",
    "    \r\n",
    "    name = model.__class__.__name__\r\n",
    "    print(name)\r\n",
    "    model_names.append(name)\r\n",
    "\r\n",
    "    model.fit(train_data.toarray(), train_labels)\r\n",
    "    pred = model.predict(test_data.toarray())\r\n",
    "\r\n",
    "    test[name]=pred"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-35-b0a67b544caa>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC\n",
      "AdaBoostClassifier\n",
      "KNeighborsClassifier\n",
      "GaussianNB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-35-b0a67b544caa>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<ipython-input-35-b0a67b544caa>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<ipython-input-35-b0a67b544caa>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<ipython-input-35-b0a67b544caa>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<ipython-input-35-b0a67b544caa>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing for Fairness\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## testing one model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tester = FairnessTester()\r\n",
    "tester.setup(test, protected_att, priv_val, unpriv_val)\r\n",
    "print(\"privileged confusion: \\n\",tester.priv_confusion_matrix())\r\n",
    "print(\"unprivileged confusion: \\n\", tester.unpriv_confusion_matrix())\r\n",
    "tester.confuison_based_dic()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## testing classifiers list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "tester = FairnessTester()\r\n",
    "\r\n",
    "\r\n",
    "result_df = pd.DataFrame()\r\n",
    "\r\n",
    "for name in model_names:\r\n",
    "    tester.setup(test, protected_att, priv_val, unpriv_val, name)\r\n",
    "    result_dic = {\"model\": name}\r\n",
    "    result_dic.update(tester.confusion_based_dic_priv())\r\n",
    "    result_df= result_df.append(result_dic, ignore_index=True)\r\n",
    "    \r\n",
    "    result_dic = {\"model\": name}\r\n",
    "    result_dic.update(tester.confusion_based_dic_unpriv())\r\n",
    "    result_df= result_df.append(result_dic, ignore_index=True)\r\n",
    "definitions_names = list(tester.confuison_based_dic().keys())\r\n",
    "result_df\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\makra\\Documents\\Thesis\\fairnesTester.py:103: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     model   group  statistical parity  predictive parity  \\\n",
       "0   DecisionTreeClassifier    priv            0.901639           0.818182   \n",
       "1   DecisionTreeClassifier  unpriv            0.872549           0.943820   \n",
       "2   RandomForestClassifier    priv            0.983607           0.816667   \n",
       "3   RandomForestClassifier  unpriv            0.990196           0.920792   \n",
       "4                      SVC    priv            0.950820           0.827586   \n",
       "5                      SVC  unpriv            0.970588           0.939394   \n",
       "6       AdaBoostClassifier    priv            0.836066           0.823529   \n",
       "7       AdaBoostClassifier  unpriv            0.931373           0.947368   \n",
       "8     KNeighborsClassifier    priv            0.934426           0.807018   \n",
       "9     KNeighborsClassifier  unpriv            0.970588           0.939394   \n",
       "10              GaussianNB    priv            0.786885           0.895833   \n",
       "11              GaussianNB  unpriv            0.823529           0.940476   \n",
       "\n",
       "    negative predictive parity  equal opportunity  predictive equality  \\\n",
       "0                     0.333333           0.918367             0.833333   \n",
       "1                     0.230769           0.893617             0.625000   \n",
       "2                     1.000000           1.000000             0.916667   \n",
       "3                     0.000000           0.989362             1.000000   \n",
       "4                     0.666667           0.979592             0.833333   \n",
       "5                     0.666667           0.989362             0.750000   \n",
       "6                     0.300000           0.857143             0.750000   \n",
       "7                     0.428571           0.957447             0.625000   \n",
       "8                     0.250000           0.938776             0.916667   \n",
       "9                     0.666667           0.989362             0.750000   \n",
       "10                    0.538462           0.877551             0.416667   \n",
       "11                    0.166667           0.840426             0.625000   \n",
       "\n",
       "    overall accuracy equality  treatment equality  \n",
       "0                    0.770492           10.208333  \n",
       "1                    0.852941            5.875000  \n",
       "2                    0.819672                 inf  \n",
       "3                    0.911765           94.000000  \n",
       "4                    0.819672           40.833333  \n",
       "5                    0.931373           70.500000  \n",
       "6                    0.737705            5.250000  \n",
       "7                    0.911765           14.687500  \n",
       "8                    0.770492           14.972222  \n",
       "9                    0.931373           70.500000  \n",
       "10                   0.819672            3.402778  \n",
       "11                   0.803922            3.916667  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>group</th>\n",
       "      <th>statistical parity</th>\n",
       "      <th>predictive parity</th>\n",
       "      <th>negative predictive parity</th>\n",
       "      <th>equal opportunity</th>\n",
       "      <th>predictive equality</th>\n",
       "      <th>overall accuracy equality</th>\n",
       "      <th>treatment equality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>10.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>5.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>priv</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>40.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>70.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>14.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>14.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>70.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>priv</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>3.402778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>3.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "result_df\r\n",
    "full_result_df = pd.DataFrame()\r\n",
    "for model in model_names:\r\n",
    "    for defi in definitions_names:\r\n",
    "        for group in [\"priv\", \"unpriv\"]:            \r\n",
    "            dic = {}\r\n",
    "            dic[\"model\"] = result_df.loc[(result_df[\"model\"]==model)&(result_df[\"group\"]==group)][\"model\"].item()\r\n",
    "            dic[\"group\"] = result_df.loc[(result_df[\"model\"]==model)&(result_df[\"group\"]==group)][\"group\"].item()\r\n",
    "            dic[\"definition\"] = defi\r\n",
    "            dic[\"result\"]= result_df.loc[(result_df[\"model\"]==model)&(result_df[\"group\"]==group)][defi].item()\r\n",
    "            full_result_df = full_result_df.append(dic, ignore_index=True)\r\n",
    "\r\n",
    "full_result_df\r\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     model   group                  definition    result\n",
       "0   DecisionTreeClassifier    priv          statistical parity  0.901639\n",
       "1   DecisionTreeClassifier  unpriv          statistical parity  0.872549\n",
       "2   DecisionTreeClassifier    priv           predictive parity  0.818182\n",
       "3   DecisionTreeClassifier  unpriv           predictive parity  0.943820\n",
       "4   DecisionTreeClassifier    priv  negative predictive parity  0.333333\n",
       "..                     ...     ...                         ...       ...\n",
       "67              GaussianNB  unpriv           equal opportunity  0.840426\n",
       "68              GaussianNB    priv         predictive equality  0.416667\n",
       "69              GaussianNB  unpriv         predictive equality  0.625000\n",
       "70              GaussianNB    priv   overall accuracy equality  0.819672\n",
       "71              GaussianNB  unpriv   overall accuracy equality  0.803922\n",
       "\n",
       "[72 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>group</th>\n",
       "      <th>definition</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>statistical parity</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>statistical parity</td>\n",
       "      <td>0.872549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>predictive parity</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>predictive parity</td>\n",
       "      <td>0.943820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>priv</td>\n",
       "      <td>negative predictive parity</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>equal opportunity</td>\n",
       "      <td>0.840426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>priv</td>\n",
       "      <td>predictive equality</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>predictive equality</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>priv</td>\n",
       "      <td>overall accuracy equality</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>unpriv</td>\n",
       "      <td>overall accuracy equality</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "plots = []\r\n",
    "for definition in definitions_names:\r\n",
    "\r\n",
    "    plot = p9.ggplot(data= result_df, mapping = p9.aes(x=\"model\", y=definition)) + p9.geom_col()+p9.facet_grid(\"group~.\") + p9.theme(axis_text_x = p9.element_text(angle=90))\r\n",
    "    plots.append(plot) \r\n",
    "\r\n",
    "i=0\r\n",
    "for plot in plots:\r\n",
    "    plot.save(filename=\"plots/\"+dataset_name+\"_\"+definitions_names[i]+\".png\")\r\n",
    "    i+=1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_statistical parity.png\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_predictive parity.png\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_negative predictive parity.png\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_equal opportunity.png\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_predictive equality.png\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_overall accuracy equality.png\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_treatment equality.png\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "plot = (p9.ggplot(data= full_result_df, mapping = p9.aes(x=\"model\", y=\"result\")) \r\n",
    "    + p9.geom_col()\r\n",
    "    + p9.facet_grid(\"group~definition\", space=\"free_x\", scales=\"free\") \r\n",
    "    + p9.theme(axis_text_x = p9.element_text(angle=90))\r\n",
    "    + p9.labs(x=\"ML Models\", y= \"Results\", title=(\"Results for \" + dataset_name))\r\n",
    "    )\r\n",
    "plot.save(filename=\"plots/\"+dataset_name+\"_complete.png\", height=4 , width = 17)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Saving 17 x 4 in image.\n",
      "C:\\Users\\makra\\anaconda3\\envs\\code\\lib\\site-packages\\plotnine\\ggplot.py:722: PlotnineWarning: Filename: plots/student_performance_dataset_complete.png\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('code': conda)"
  },
  "interpreter": {
   "hash": "e5ece89884ccebb975b7476b07cac838ebecb97f5ba3e39f6a5146932c714791"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}